1.Spark采用RDD以后能够实现高效计算的原因在于：
    -1.高效的容错性
        . 现有的容错机制：数据复制或者记录日志
        . RDD：血缘关系、重新计算丢失分区、无需回滚系统、重算过程在不同节点之间并行、只记录粗粒度的操作
    -2.中间结果持久化到内存，数据在内存中的多个RDD操作之间进行传递，避免了不必要的读写磁盘开销
    -3.存放的数据可以是JAVA对象，避免了不必要的对象序列化和反序列化
2.作业划分阶段的依据：宽依赖和窄依赖
    宽依赖：无法优化
    窄依赖：对于作业的优化有利
3.每个RDD操作都是一个fork/join（一种用于并行执行任务的框架），把计算fork到每个RDD分区，完成计算后对各个分区得到的结果进行Join操作，然后fork/
    join下一个RDD操作
4.Stage的划分方法：
    -1.在DAG中进行反向解析，遇到宽依赖就断开
    -2.遇到窄依赖就把当前的RDD加入到Stage中
    -3.将窄依赖尽量划分在同一个Stage中，可以实现流水线计算
5.RDD在Spark架构中的运行过程：
    -1.创建RDD对象
    -2.SparkContext负责计算RDD之间的依赖关系，构建DAG
    -3.DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor
        去执行。


