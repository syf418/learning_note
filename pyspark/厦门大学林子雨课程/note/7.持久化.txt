1.RDD持久化
    在Spark中，RDD采用惰性求值的机制，每次遇到行动操作，都会从头开始执行计算。每次调用行动操作，都会触发一次从头开始的计算。这对于迭代计算而言
  代价是很大的。
      * 可以通过持久化（缓存）机制避免这种重复计算的开销。
      * 可以使用persist()方法对一个RDD标记为持久化，标记的意思是遇到行动操作才会进行持久化。
      * 持久化后的RDD将会被保留在计算节点的内存中被后面的行动操作重复使用。
2.persist()的圆括号中包含的是持久化级别参数：
    -1.persist(MEMORY_ONLY): 表示将RDD作为反序列化的对象存储于JVM中，如果内存不足，就要按照LRU原则替换缓存中的内容。
    -2.persist(MEMORY_AND_DISK): 表示将RDD作为反序列化的对象存储在JVM中，如果内存不足，超出的分区将会被存放在硬盘上。
    ->：一般而言，使用cache()方法时，会调用persist(MEMORY_ONLY)
    ->: 可以使用unpersist()方法手动地把持久化的RDD从缓存中移除。

